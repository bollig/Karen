\chapter{Introduction}

\begin{itemize} 
	\item Background of  the Problem/Study
	\item Statement of the Problem 
	\item Purpose of the Study (including hypothesis or research question)
	\item Research Questions
	\item Importance of the Study (why should the reader care?)
	\item Scope of the Study
	\item Definition of Terms
	\item Limitations
\end{itemize} 

%------------------------------

\section{Radial Basis Function Methods for PDEs}

\begin{itemize}
\item Easily extend to higher dimensions
\item High rate of convergence (exponential for global RBFs)
\item Successful applications to wide range of geophysical applications
\item Global, Compact, FD, MQ-FD, DQ-FD, and even DRBEM methods
\item We emphasize RBF-FD due to its low computational complexity and parallel nature
\end{itemize} 

\section{RBF-FD applications} 
\begin{itemize} 
	\item RBF-FD is applied to hyperbolic PDEs (Flyer, Wright, Lehto, Fornberg, etc)
	\item RBF-FD applied to elliptic PDEs 
	\item We study RBF-FD in context of hyperbolic advection and incompressible fluid flow.
\end{itemize} 

\section{RBF Parallelism}
\begin{itemize} 
	\item Parallel Global RBF papers
	\item Parallel CSRBF papers
	\item Not much parallelism in the field, so we introduce it via parallel SpMV and parallel preconditioned GMRES
\end{itemize} 

\section{GPU Computing} 
\begin{itemize} 
	\item Only Schmidt consider GPU for RBFs
	\item Beyond the parallel (MPI applications, we port everything to the GPU to leverage the high FLOP per watt hardware. 
\end{itemize} 

\section{Major Challenges}
Disclaimer: RBF-FD is young. As such, 
\begin{itemize}
	\item never parallelized
	\item hand-written code (both CPU and GPU)
	\item Few test cases
	\item My role:
	\begin{itemize} 
	\item Developed test cases (Elliptic, Stokes) which were not seen before
	\item Had to verify method convergence, stability, conditioning, etc for test cases before optimization
	\item Attempted to build components required for a large 3D mantle convection code
	\item Blind implementation to solve PDEs (learned a lot, but wasted lots of time learning about PDEs). 
	\item Original view: Weights times solution values; Current view: Sparse matrix times solution vector. Different perspective makes huge difference in code and parallellization approach.
	\item Resulted in minimal optimization to components
	\end{itemize} 
\end{itemize} 



This thesis should outline details of all the research I have done for the dissertation. Topics include 

parabolic pdes on ellipse and ellipsoid
    - Test by monitoring linf norm
    - node distributions with CVT make sure projection works (octree to test distance)
    - first GPU kernels with boundary condition kernel as well 
elliptic pdes on annulus
    - Test by dirichlet manufactured solution convergence
    - Describe neumann and robin boundary conditions
    - Test my parallel GMRES on this
    - Preconditioners ILU0, etc.
hyperbolic
    - repeat paper
stokes
    - parallel gmres
    - preconditioners (dig up more)
node ordering
    - impact on conditioning
    - coloring and cuthill mckee alternatives
    - need complexity and benchmark comparison of kdtree vs LSH (benchmark for
    various stencil sizes and node sizes
Optimization of sparse matrix vector multiply and overlapping communication/computation
    - Preconditioner on the GPU (Also solve weights on the GPU)
    - Occupancy, GFLOPS, speedup

Contribs: 
    - RBF-FD to 3 PDE types on the GPU
    - Scalable multi-GPU implementation
    - Up to 20x speedup (Given spear results; need faster)
    - Multi-GPU GMRES with preconditioners
    - Qs: 
        - How to get scalable implementation? Minimize comm and occupied memory
        (span vector across CPUs)
        - How to hide GPU upload/download? Overlap comm and comp.
        - How much extra efficiency from node ordering? 
        - How much reduction in bandwidth from node ordering?
        - Which node ordering gives best bandwidth and conditioning?
        - How to tie down nullspace for stokes on sphere?
        - How to precondition RBF-FD? 
        - How to stabilize the bell advection with velocity (12 days)? Is it
        the same as a single operator (TODO)? 
        - How does splitting operator impact hyperviscosity and eigenvalues? 
        - How does CVT with support function converge? Support function is for
        uniform on sphere, how does it compare to CVT in box?
        - Can we color the graph from RBF-FD to get better parallelism in GPU? 
        - Is it possible to use RBF-FD in single precision? Start by comparing
        accuracy of weights for single and double precision. What are the
        contours for single/double precision? Can we compute inverse of system
        with single precision (Perhaps we need iterative method?)?
        - 

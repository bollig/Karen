
\makeatletter
\@ifundefined{standalonetrue}{\newif\ifstandalone}{}
\@ifundefined{section}{\standalonetrue}{\standalonefalse}
\makeatother
\ifstandalone
\documentclass{report}

\input{all_usepackages} 
\usepackage[margin=1.25in]{geometry}

\begin{document}
\fi

\chapter{GPU SpMV}

\section{Related Work}
\cite{Bell2009} \cite{Kreuzer2012}
\cite{Vuduc2005} etc. 

\section{GPGPU}
GPGPU evolution
\subsection{OpenCL}
OpenCL is chosen with the future in mind. Hardware changes rapidly and vendors often leapfrog one another in the performance race. By selecting OpenCL, we hedge our bets on the functional portability

\subsection{Hardware Layout}
Modern GPUs have a memory hierarchy and hardware layout. 

\subsection{Expectations in Performance}
Many GPU applications claim a 50x or higher speedup. This will never be the case for RBF-FD for the simple reason that the method reduces to an SpMV. The SpMV is a low computational complexity operation with only two operations for every one memory load. 

\section{Targeting the GPU}

\subsection{OpenCL}
\subsection{Naive Kernels}
\subsection{SpMV Formats/Kernels}

\section{Performance Comparison}
\subsection{Performance of Cosine CL vs VCL}
\subsection{VCL Formats Comparison}

Our assumption with RBF-FD in this manuscript is that all stencils will have equal size. Due to this, the ELL format is preferred as the default. 
 

\chapter{Distributed Solver}
\label{sec:rbffd_gpu}

Distributed application of RBF-FD requires three
design decisions \cite{Saad2003}. First, the problem is partitioned in some fashion to distribute work across multiple processes. Intelligent partitioning
impacts load balancing of processors and the ratio of computation versus communication; imbalanced computation can result in excessive delay per
iteration as some processors tackle larger problem sizes while others sit idle, waiting on information. Second, one must determine whether processes have access to all or a subset of node information,
solution values, etc. and establish index mappings that translate between a local context and the global problem. Last but not least, the local ordering  processor can re-order nodes locally in an
effort to improve solver efficiency and local system conditioning. Node
ordering is also significant in the future discussion of offloading computation to GPUs as it can help to minimize data transfer between CPU and GPU. 


Parallelization of the RBF-FD method is achieved at two levels. First, the
physical domain of the problem\hl{---in this case, the unit sphere---}is partitioned
into overlapping subdomains, each handled by a different CPU process. All CPUs
operate independently to compute/load RBF-FD stencil weights, run diagnostic
tests and perform other initialization tasks. A CPU computes only weights
corresponding to stencils centered in the interior of its partition. After
initialization, CPUs continue concurrently to solve the PDE. Communication
barriers ensure that the CPUs execute in lockstep to maintain consistent
solution values in regions where partitions overlap.  The second level of
parallelization offloads time-stepping of the PDE to the GPU.  Evaluation of
the right hand side of Equation~(\ref{eq:evaluation_with_hyperviscosity}) is
data-parallel: the solution derivative at each stencil center is evaluated
independently of the other stencils. This maps well to the GPU, offering decent
speedup even in unoptimized kernels. Although the stencil weight calculation is
also data-parallel, we assume that in this context that the weights are
precomputed and loaded once from disk during the initialization phase. 

%TODO: Need partitioning, global and local index maps, and local ordering for a distributed matrix operation \cite{Saad2003} 

\section{Partitioning}

For ease of development and parallel debugging, partitioning is initially
assumed to be linear within one physical direction (typically the
$x$-direction). Figure~\ref{fig:decomposed_sphere} illustrates a partitioning of
$N=10,201$ nodes on the unit sphere onto four CPUs. Each partition, illustrated
as a unique color, represents set $\setAllNodes$ for a single CPU.  Alternating
representations between node points and interpolated surfaces illustrates the
overlap regions where nodes in sets $\mathcal{O}$ and $\mathcal{R}$ (i.e., nodes
requiring MPI communication) reside. As stencil size increases, the width of the
overlap regions relative to total number of nodes on the sphere also increases. 

\authnote{Q: what is the percentage overlap for $n$? $\frac{1}{2} n^{\frac{1}{d}}$ gives depth into neighbor since n is uniformly sampled we expect a cube shape. (SHould be literature on this...no?)} % assume sphere, sqrt of N for scaling area covered by stencil}


The linear partitioning in Figure~\ref{fig:decomposed_sphere} was chosen for ease of implementation. Communication is limited for each
processor to left and right neighbors only, which simplifies parallel debugging. This partitioning, however, does not guarantee properly balanced computational work-loads. \authnote{Update w/ ParMETIS} Other partitionings of the sphere exist but are not studied here because this paper's focus is neither on efficiency nor on selecting a partitioning strategy for maximum accuracy. Examples of alternative approaches include a cubed-sphere \cite{Ivan2011} or icosahedral geodesic grid \cite{Randall2002}, which can evenly balance the computational load across partitions. Other interesting partitionings can be generated with software libraries such as the METIS \cite{Karypis1999} family of algorithms, capable of partitioning and reordering directed graphs produced by RBF-FD stencils. 

\begin{figure}[ht!]
\begin{center}
\includegraphics[width=2.5in]{../figures/paper1/figures/vortex_rollup/4procs_N10K_n31.pdf}
\caption{Partitioning of $N=10,201$ nodes to span four processors with stencil size $n=31$. }
\label{fig:decomposed_sphere}
\end{center}
\end{figure}

%TODO: Need to flesh detail on METIS


\begin{figure}[ht!]
\begin{center}
\includegraphics[width=0.8\textwidth]{rbffd_methods_content/decompositions/gpmetis_decomp_sphere_4parts.png}
\caption{METIS partitioning of $N=10,201$ nodes to span four processors with stencil size $n=31$.  }
\label{fig:decomposed_sphere}
\end{center}
\end{figure}

\begin{figure}[ht!]
\begin{center}
\includegraphics[width=0.45\textwidth]{rbffd_methods_content/decompositions/MatrixDecompositionSets_RBF-FD_Bowed.pdf} 
\caption{Decomposition for one processor selects a subset of rows from the DM. Blocks corresponding to node sets $\setCenters \backslash \setBoundary$, $\setProvide$, and $\setDepend$ are labeled for clarity. }
\label{fig:decomp_matrix_view}
\end{center}
\end{figure}


\begin{figure}[ht!]
\begin{center}
\includegraphics[width=9cm]{rbffd_methods_content/decompositions/spy_metis_stencil_example_labels.png}
%\includegraphics[width=0.45\textwidth]{rbffd_methods_content/decompositions/spy_metis_stencil_example_part_2_of_4.pdf}
\caption{Spy of the sub-DM view on processor 2 of 4 from a METIS partitioning of $N=10,201$ nodes with stencil size $n=31$. Blocks are highlighted to distinguish node sets $\setCenters \backslash \setBoundary$, $\setProvide$, and $\setDepend$. Stencils involved in MPI communications have been permuted to the bottom of the matrix.}
\label{fig:decomp_spy}
\end{center}
\end{figure}


\section{Local node ordering}

After partitioning, each CPU/GPU is responsible for its own subset of nodes. 
To simplify accounting, we track nodes in two ways. Each node is assigned
a global index, that uniquely identifies it. This index follows the node 
and its associated data as it is shuffled between processors. In addition, 
it is important to treat the nodes on each CPU/GPU in an identical manner. 
Implementations on the GPU are more efficient when node indices
are sequential. Therefore, we also assign a local index for the nodes on 
a given CPU, which run from 1 to the maximum number of nodes on that CPU. 

It is convenient to break up the nodes on a given CPU into various sets
according to whether they are sent to other processors, are retrieved from 
other processors, are permanently on the processor, etc. Note as well, 
that each node has a home processor since the RBF nodes are partitioned into 
multiple domains without overlap.
Table~\ref{tbl:stencil_sets}, defines the collection of index lists that each CPU must maintain for both multi-CPU and multi-GPU implementations.  


Figure~\ref{fig:stencilSets2CPU} illustrates a configuration with two 
CPUs and two GPUs, and 9 stencils, four on CPU1, and five on CPU2, separated
by a vertical line in the figure. Each stencil
has size $n=5$. In the top part of the figures, the stencils are laid out
with blue arrows pointing to stencil neighbors and creating the edges of a directed adjacency graph. Note that the connection between two nodes is not 
always bidirectional. For example, node 6 is in the stencil of node 3, but 
node 3 {\em is not\/} a member of the stencil of node 6. 
Gray arrows point to stencil neighbors outside the small window and are not relevant to the following discussion, which focuses only on data flow between 
CPU1 and CPU2. 
Since each CPU is responsible for the derivative evaluation and solution updates for any stencil center, it is clear that some nodes have a stencil with nodes that are on a different CPU. For example, node 8 on CPU1 has a stencil comprised of
nodes 4,5,6,9, and itself. The data associated with node 6 must be retrieved
from CPU2. Similarly, the data from node 5 must be sent to CPU2 to 
complete calculations at the center of node 6.


The set of all nodes that a CPU interacts with is denoted by $\setAllNodes$, which includes not only the nodes stored on the CPU, but the nodes required from other CPUs to complete the calculations. 
The set $\setCenters\in\setAllNodes$ contains the nodes at which the CPU 
will compute derivatives and apply solution updates. 
The set $\setDepend = \setAllNodes \backslash \setCenters$ 
is formed from the set of nodes whose values must be retrieved from another CPU. 
For each CPU, the set $\setProvide\in\setCenters$ is sent to other CPUs. The set $\setBoundary\in\setCenters$ consists of nodes that depend on  values from $\setDepend$ in order to evaluate derivatives. Note that $\setProvide$ and $\setBoundary$ can overlap, but differ in size, since the directed adjacency graph produced by stencil edges is not necessarily symmetric. The set $\setBoundary \backslash \setProvide$ represents nodes that depend on $\setDepend$ but are not sent to other CPUs, while $\setCenters \backslash \setBoundary$ are nodes that have no dependency on information from other CPUs.
The middle section Figure~\ref{fig:stencilSets2CPU} lists global node indices contained in $\setAllNodes$ for each CPU. Global indices are paired with local indices to indicate the node ordering internal to each CPU. The structure of set $\setAllNodes$,
   \begin{equation}
 		\setAllNodes = \{ \mathcal{Q}\backslash\mathcal{B} \ \ \mathcal{B}\backslash\mathcal{O} \ \ \mathcal{O} \ \ \setDepend \},
            \label{eqn:decompose_g}
        \end{equation}
 is designed to simplify both CPU-CPU and CPU-GPU memory transfers by grouping nodes of similar type. The color of the global and local indices in the figure
 indicate the sets to which they belong. They are as follows: white represents $\setCenters \backslash \setBoundary$, 
 yellow represents $\setBoundary \backslash \setProvide$, green indices 
 represent $\setProvide$, and red represent $\setDepend$.  


        \begin{table}[t]
            \begin{center}
                \begin{tabular}{l l}
                    \hline
                    $\setAllNodes$ &: all nodes received and contained on the CPU/GPU $g$ \\
                    $\setCenters$ &: stencil centers managed by $g$ 
					(equivalently, stencils computed by $g$) \\
                    $\setBoundary$ &: stencil centers managed by $g$ that
                    require nodes from another CPU/GPU \\
                    $\setProvide$ &: nodes managed by $g$ that are sent to other CPUs/GPUs  \\
                    $\setDepend$ &: nodes required by $g$ that are managed by another CPU/GPU \\
                    \hline
                \end{tabular}
                \caption{Sets defined for stencil distribution to multiple CPUs}
                            \label{tbl:stencil_sets}
            \end{center}
        \end{table}

        \begin{figure}[ht] 
            \centering
            \includegraphics[width=3.5in]{../figures/paper1/figures/omnigraffle/SimpleExample.pdf} 
            \caption{Partitioning, index mappings and memory transfers for nine stencils ($n=5$) spanning two CPUs and two GPUs. Top: the directed graph created by stencil edges is partitioned for two CPUs. Middle: the partitioned stencil centers are reordered locally by each CPU to keep values sent to/received from other CPUs contiguous in memory. Bottom: to synchronize GPUs, CPUs must act as intermediaries for communication and global to local index translation. Middle and Bottom: color coding on indices indicates membership in sets from Table~\ref{tbl:stencil_sets}: $\setCenters \backslash \setBoundary$ is white, $\setBoundary \backslash \setProvide$ is yellow, $\setProvide$ is green and $\setDepend$ is red.
            }
            \label{fig:stencilSets2CPU}
        \end{figure}	

 The structure of $\setAllNodes$ offers two benefits: first, solution values in $\setDepend$ and $\setProvide$ are contiguous in memory and can be copied to or from the GPU without the filtering and/or re-ordering normally required in preparation for efficient data transfers. Second, asynchronous communication allows for the overlap of communication and computation. This will be considered as part of future research on algorithm optimization.  Distinguishing the set $\mathcal{B} \backslash \mathcal{O}$ allows the computation of $\mathcal{Q}\backslash \mathcal{B}$ while waiting on $\mathcal{R}$. 

\authnote{} The local index set is ordered as ${QmB, BmO, O, R}$ 

\authnote{} Domain boundary nodes appear at beginning of the list 


When targeting the GPU, communication of solution or intermediate values is a four step process:
        \begin{enumerate}
    \item Transfer $\mathcal{O}$ from GPU to CPU
	\item Distribute $\mathcal{O}$ to other CPUs, receive $R$ from other CPUs
	\item Transfer $\mathcal{R}$ to the GPU
	\item Launch a GPU kernel to operate on $\mathcal{Q}$
     \end{enumerate} 
The data transfers involved in this process are illustrated at the bottom of Figure~\ref{fig:stencilSets2CPU}.
    Each GPU operates on the local indices ordered 
according to Equation~(\ref{eqn:decompose_g}). The set 
$\setProvide$ is copied off the GPU and into CPU memory as one contiguous memory block. The CPU then maps local to global indices and transfers $\setProvide$ to other CPUs. CPUs send only the subset of node values from $\setProvide$ that is required by the destination processors, but it is important to note that node information might be sent to several destinations. 
As the set $\setDepend$ is received, the CPU converts back from global to local indices before copying a contiguous block of memory to the GPU. 

        This approach is scalable to a very large number of 
		processors, since the individual processors do not require the 
		full mapping between RBF nodes and CPUs. 
		
		By scalable here we imply total problem size and processor count. The performance scalability of the code depends on the problem size and the MPI collective. In Figure~\ref{fig:strong_scaling} the strong scaling of $N=10^6$ nodes is tested on Itasca, a supercomputer at the Minnesota Supercomputing Institute.   

\section{Communication Collectives} 
MPI collectives allow information sharing between processes. Our code leverages three collectives: MPI\_Alltoall, MPI\_Alltoallv and MPI\_Isend/MPI\_Irecv. 

The collective operation is essentially transposing information as seen in Figure~\ref{fig:mpi_alltoallv_visual}. 

MPI\_Alltoall requires that all processors send and receive an equivalent number of bytes to one another. Since the size must be equivalent for all processors, the send and receive buffers are padded to the maximum message size for any one connection between processors. MPI\_Alltoallv reduces the number of bytes sent and received by allowing processors to specify variable message sizes when communicating. For a small number of processors the variable message size will function well. However, MPI\_Alltoallv requires all processes to connect with every other process, even in the event that 0 bytes are to be sent. Based on the grid decomposition, processors compute on contiguous partitions with a small number of neighboring partitions. By replacing the MPI\_Alltoallv with a MPI\_Isend/MPI\_Irecv combination, the number of collective connections are truncated such that processors only connect to and communicate with essential neighbors that need/provide data. 

The actual implementation of MPI\_Alltoall and MPI\_Alltoallv likely use Isend and Irecv internally. 

\begin{figure}[ht!]
\begin{center}
\includegraphics[width=9cm]{../figures/omnigraffle/MPI_Alltoall_Visual.png}
\caption{The MPI\_Alltoall collective allows processors to interchange/transpose data by passing an equivalent number of bytes to every other processor.}
\label{fig:mpi_alltoall_visual}
\end{center}
\end{figure}
\begin{figure}[ht!]
\begin{center}
\includegraphics[width=9cm]{../figures/omnigraffle/MPI_Alltoallv_Visual.png}
\caption{The MPI\_Alltoallv collective compresses the interchange from MPI\_Alltoall by allowing for variable message sizes between all processors. Assume message sizes are proportional to square size in figure.}
\label{fig:mpi_alltoallv_visual}
\end{center}
\end{figure}
\begin{figure}[ht!]
\begin{center}
\includegraphics[width=9cm]{../figures/omnigraffle/MPI_IsendIrecv_Visual.png}
\caption{The MPI\_Isend/MPI\_Irecv collective allows for variable message sizes, and truncates the number of connections between processors to only required connections.}
\label{fig:mpi_isendirecv_visual}
\end{center}
\end{figure}

MPI\_Isend/MPI\_Irecv also allows for overlapping communication and computation by posting receives early 



\section{CPU Scaling}

\authnote{Show the strong and weak scaling here}

To demonstrate the effectiveness of our decomposition and indexing, we perform scaling experiments. 

Strong scaling tests the growth in time for a fixed total problem size, and a variable number of processors. 

Weak scaling considers the amount of time for a fixed problem size per process and variable number of processors. That is to say, each processor has roughly the same amount of work, so as we scale to a large number of processors, changes in time will be the result of increased communication overhead. 

We consider a simple idealized problem where derivatives are computed over a regular grid generated in 3-D. The experiment computes the SpMV one thousand times. At the end of each SpMV the MPI\_Alltoallv collective is used to synchronize the local derivative vectors. After one thousand iterations, each process computes the local norm of the resulting vector and an MPI\_Reduce collective dra


\begin{figure} 
\centering
\includegraphics[width=5cm]{performance_content/scaling/strong_scaling_4M_regular_alltoallv.png}  
\includegraphics[width=5cm]{performance_content/scaling/strong_scaling_4M_regular_alltoallv_speedup.png} \\
\includegraphics[width=5cm]{performance_content/scaling/strong_scaling_4M_regular_spmvOnly.png}
\includegraphics[width=5cm]{performance_content/scaling/strong_scaling_4M_regular_alltoallv_commOnly.png} 
\caption{Strong scaling the distributed SpMV for $N=4096000$ nodes (i.e., a $160^3$ regular grid) and various stencil sizes. Here the MPI\_Alltoallv collective operation is used. (Left) Strong scaling of SpMV (including cost of communication). (Center) Strong scaling of computation only. (Right) Strong scaling of communication only.}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=5cm]{performance_content/scaling/strong_scaling_4M_regular_n17comparison_commOnly.png}
\caption{Scaling comparison of MPI\_Alltoallv and two types of MPI\_Isend/MPI\_Irecv collectives: one with MPI\_Irecv issued after filling the MPI\_Isend send buffer (post-fill), and the other issued before filling the MPI\_Isend buffer (pre-fill).}
\end{figure}

\begin{figure}
\centering
\includegraphics[width=5cm]{performance_content/scaling/weak_scaling_np4000_regular_alltoallv_commOnly.png}
\includegraphics[width=5cm]{performance_content/scaling/weak_scaling_np4000_regular_alltoallv.png}  
\includegraphics[width=5cm]{performance_content/scaling/weak_scaling_np4000_regular_n17_compare_commOnly.png} \\
\includegraphics[width=5cm]{performance_content/scaling/weak_scaling_np4000_regular_spmvOnly.png} 
\includegraphics[width=5cm]{performance_content/scaling/weak_scaling_np4000_regular_n17_compare.png}
\caption{Weak scaling of the SpMV}
\end{figure}


\begin{figure}
\centering
\includegraphics[width=10cm]{performance_content/scaling/strong_scaling_4M_regular_isend.png}  
\includegraphics[width=10cm]{performance_content/scaling/weak_scaling_np4000_regular_isend.png}  
\caption{Scaling of SpMV with MPI\_Isend/MPI\_Irecv}
\end{figure}


\chapter{Distributed GPU SpMV}


Distributing SpMV across multiple GPUs poses a new problem: as previous mentioned, the data sent and received via MPI collectives must be copied from device to host and vice-versa. To amortize this cost we introduce a novel overlapping algorithm to hide the cost of communication behind the cost of a concurrent SpMV on the GPU. 

\section{Overlapped Queues}

\section{Avoiding Copy Out}

\subsection{Avoiding Copy-Out on CPU}

\section{Scaling}
We scale the SpMV across the GPUs on Cascade.

\subsection{Fermi}
\subsection{Kepler}

\subsection{Shared K20s}


\ifstandalone
\bibliographystyle{plain}
\bibliography{merged_references}
\end{document}
\else
\expandafter\endinput
\fi


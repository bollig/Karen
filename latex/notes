- Need to explain: 
	ELL
	CSR
	COO
	GPU hardware
	OpenCL
	Where does the GFLOP rate come from
	MPI benchmarks where is the time spent?
	PDEs
	GMRES algorithm (high level; refer to other papers)
	GPU SpMV vs CPU SpMV
	CPU SpMV in UBLAS, MKL(?)

	SpMV on GPU for increasing N (generate new regular grids now that KDTree works well) 

- Need benchmarks: 

    How does SpMV strongly scale as n varies and N is 4096000
        -> tells us how stencil size impacts overlap and how MPI time grows
    How does SpMV weakly scale as N varies for multiple n? 
        -> Tells us how efficient the 


Gather related work on SpMV and Distributed
Write algorithms for SpMV
	Many problems have simple stencils that can be coded directly. e.g., 5-point
	Simply state that initial attempts did what we did
	Then say considering the fact that SpMV has low computational complexity we anticipate it will be memory bound. 
	Then say that if this is true we need to improve memory layout and reduce memory load overhead
	Then say formats are best optimization. 
	Expectations: what are teh GFLOPs achieved by each implementation? What is the peak possible for 2:1 complexity? 
	How does ViennaCL allow control of blocks, tuning? 
Write algorithms for Distributed


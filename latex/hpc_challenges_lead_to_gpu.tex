\section{HPC: Memory and Parallelism}

Two principal challenges exist in all high performance computing applications: overcoming storage hierarchy limitations and properly utilizing available parallelism. Properly addressing each challenge can result in performance improvements. 

Limiting factors in memory are access speed (voltage) and 

Since the advent of computing, multiple tiers of memory have existed, with each level representing a tier of cost vs. speed. The faster the memory, the more it costs. This trade-off leads to a deep memory hierarchy in which the fastest memory exists closest to the compute cores, but is smallest by quantity. This paradigm is well established and widely accepted in computing on CPUs. 

With the advent of GPU computing, a new round of accelerator hardware was introduced, replete with an internal hierarchy of memory and massively parallel compute units. 
%!TEX root = karen.tex

These figures represent optimizations of the Cosine Bell and Vortex Roll-up test cases. Essentially, the optimizations here are general for multi-GPU SpMV. Improving these test cases improves all explicit schemes for RBF-FD (i.e., hyperbolic and parabolic equations, and various time stepping schemes like euler, RK4, Adams-Bashforth etc.). 


\section{MPI\_Alltoallv}

Communication between processors requires each processor to iterate through their neighboring processors and share information. This can be seen as a simple for loop allowing every processor to touch its neighbors in round-robin fashion. The benchmarks seen in \authnote{figures from paper1} show the strong scaling of our implementation with a for loop and send/recv. 

In Figs~\ref{figs:alltoall_scaling} we show the strong scaling of the cosine bell after 

Alternatively

an all to all collective. That is, all processors share some information with potentially every other processor. 